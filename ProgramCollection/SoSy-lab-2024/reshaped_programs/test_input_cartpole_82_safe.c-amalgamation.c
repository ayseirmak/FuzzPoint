#include <stdio.h>
#include <stdint.h>
#include <assert.h>

void entry(const float tensor_input[1][4], float tensor_output[1][2]);

int main() {
    // Initialize with fixed deterministically chosen inputs within the specified range.
    float tensor_input[1][4] = {
        {0.44f, -0.295f, 0.06f, 0.33f}
    };
    float tensor_output[1][2];

    entry(tensor_input, tensor_output);

    // Assert the condition: tensor_output[0][0] should not be <= tensor_output[0][1].
    assert(!(tensor_output[0][0] <= tensor_output[0][1]));

    printf("Execution completed successfully.\n");

    return 0;
}

// This file is computer-generated by onnx2c

#include <float.h>
#include <math.h>
#include <string.h>
#define MAX(X, Y) ((X) > (Y) ? (X) : (Y))
#define MIN(X, Y) ((X) < (Y) ? (X) : (Y))
#define CLIP(X, L) (MAX(MIN(X, L), -L))

static const float tensor_q_net_0_weight[64][4] = {
  {0.15721032f, 0.11475459f, -0.63993812f, -0.06951085f},
  {0.17542747f, 0.03734675f, 0.118049f, -0.42608327f},
  {0.17451042f, -0.03839092f, -0.12378699f, 0.16069195f},
  {-0.27305022f, -0.08558031f, 0.75955445f, 0.51875508f},
  {-0.36573705f, -0.24695796f, 0.54157341f, -0.10584691f},
  {-0.06535788f, -0.29461735f, -0.86868924f, -0.42447931f},
  {-0.1669663f, -0.4495599f, -0.46123439f, -0.02098111f},
  {-0.66190141f, -0.23531131f, 0.62862229f, -0.27901083f},
  {0.17868228f, 0.3591108f, 0.14576785f, -0.39424306f},
  {-0.65974438f, 0.15513201f, 0.15558757f, -0.16923116f},
  {-0.06038467f, 0.48458999f, -0.49716309f, -0.3113912f},
  {-0.19236545f, 0.017238077f, 0.31643331f, 0.11882078f},
  {0.077491581f, -0.45291129f, -0.24384044f, -0.17995878f},
  {0.49704143f, 0.082509786f, -0.20520923f, -0.29227844f},
  {-0.52873462f, 0.022500124f, -0.080530085f, 0.47344843f},
  {-0.3524875f, -0.16583487f, -0.013518643f, 0.023007425f},
  {-0.42581609f, 0.052996643f, 0.39690676f, -0.26001734f},
  {0.33361933f, 0.29740149f, 0.56780291f, 0.19177464f},
  {-0.11368326f, -0.27305487f, 0.26973405f, 0.23418289f},
  {0.075950943f, 0.18417342f, 0.61009067f, 0.26281381f},
  {-0.39552087f, -0.0428917f, -0.21572167f, -0.058940869f},
  {-0.57776517f, 0.47246569f, -0.25832871f, 0.36092243f},
  {0.10012031f, -0.18621048f, -0.22833109f, 0.031087309f},
  {0.38490218f, -0.49956322f, -0.47275031f, 0.077935919f},
  {0.30921569f, -0.42641988f, -0.40230367f, -0.40324175f},
  {0.63655609f, 0.21062851f, -0.65637255f, 0.46128243f},
  {-0.38448632f, 0.10538971f, 0.49003175f, 0.052914798f},
  {-0.42741406f, 0.37639019f, 0.59647685f, -0.45300826f},
  {0.2783913f, -0.15608096f, -0.47896218f, -0.43156555f},
  {-0.53123921f, 0.49752474f, 0.03289967f, 0.10219133f},
  {-0.1347708f, -0.38954327f, -0.43758768f, -0.27198565f},
  {0.19732492f, -0.35278046f, -0.1018737f, -0.27081883f},
  {-0.042072766f, 0.44140005f, -0.13818964f, -0.18287838f},
  {-0.34508318f, 0.47647181f, 0.24145375f, 0.40118521f},
  {-0.30380112f, -0.29507232f, -0.025434055f, 0.3262502f},
  {-0.27462953f, 0.0008958446f, -0.17577507f, 0.11180936f},
  {0.63477182f, -0.13386686f, -0.64766479f, -0.44009039f},
  {-0.12738857f, 0.48643681f, -0.1750367f, 0.3937684f},
  {0.68278217f, 0.01837841f, -0.16910094f, -0.50995582f},
  {-0.49679357f, 0.026661411f, 0.1381067f, 0.53860599f},
  {-0.005378791f, -0.14719725f, 0.36476159f, -0.063192755f},
  {-0.10614252f, 0.48463655f, 0.34106863f, -0.45423216f},
  {0.31066701f, -0.0033910142f, 0.30815017f, 0.30849862f},
  {0.17261598f, 0.48857433f, 0.30169779f, -0.06020426f},
  {0.31123096f, 0.3343761f, 0.12725288f, -0.38050139f},
  {0.55887973f, 0.45446309f, -0.54596186f, -0.21886797f},
  {0.31797805f, 0.40895954f, 0.59627885f, 0.23894858f},
  {0.30402878f, -0.44058898f, 0.14562137f, -0.17414567f},
  {-0.27986199f, 0.15126775f, -0.022729687f, 0.2511293f},
  {-0.10832309f, 0.23695551f, 0.73702902f, -0.36840069f},
  {-0.2738277f, 0.26596126f, 0.20365368f, 0.31078708f},
  {0.28197551f, 0.46804509f, 0.56256306f, 0.17713961f},
  {0.29725003f, -0.15884678f, -0.060288373f, 0.065528862f},
  {0.60779554f, -0.12328117f, -0.69134706f, -0.40284744f},
  {0.48629779f, -0.3183203f, -0.62152892f, 0.34267014f},
  {-0.67640513f, 0.28546536f, 0.55224311f, 0.45257029f},
  {-0.48299044f, -0.48568195f, 0.52203935f, -0.19417253f},
  {0.13328588f, -0.32945892f, 0.41532999f, 0.18933499f},
  {-0.44472277f, -0.3517563f, 0.2564559f, 0.41243953f},
  {0.51961446f, -0.53158933f, 0.1874281f, 0.3360866f},
  {-0.28276044f, 0.30912891f, 0.35654855f, -0.36720178f},
  {-0.19587864f, -0.25889432f, -0.1390612f, 0.37115163f},
  {-0.30637884f, 0.053323369f, 0.41713884f, -0.05785262f},
  {0.11183704f, -0.091638505f, -0.62372941f, -0.40521082f}
};
static const float tensor_q_net_0_bias[64] = {
-0.038480949f, 0.12814425f, 0.49260348f, -0.30465084f, 0.3525427f, -0.26110908f, 0.20527217f, 0.10104731f, 0.57948935f, 0.17996396f, -0.21129723f, 0.43121445f, 0.40312266f, -0.48459199f, -0.4562057f, 0.44695967f, 0.44353476f, 0.1712577f, -0.25991657f, -0.053610563f, 0.51717705f, 0.50246847f, 0.38229704f, 0.33439946f, -0.17707166f, 0.21073416f, -0.26519129f, -0.016289037f, 0.034695562f, 0.087283738f, 0.24151175f, 0.53101653f, -0.3251664f, 0.39164531f, 0.4672716f, 0.3406541f, -0.18368705f, 0.24994476f, -0.22628303f, -0.023869842f, 0.51308519f, 0.3623333f, -0.32683113f, -0.030779188f, 0.32206705f, -0.53335619f, 0.38285783f, 0.35463357f, -0.17398751f, 0.45185545f, -0.11234467f, 0.57393497f, 0.43061343f, -0.29271811f, 0.40734163f, -0.26300088f, -0.1739918f, -0.44128191f, -0.40234718f, 0.33810994f, 0.32970127f, 0.2734957f, 0.20511501f, 0.081185646f};
static const float tensor_q_net_2_weight[64][64] = { /* the data is truncated here */ };
static const float tensor_q_net_2_bias[64] = { /* the data is truncated here */ };
static const float tensor_q_net_4_weight[2][64] = { /* the data is truncated here */ };
static const float tensor_q_net_4_bias[2] = { /* the data is truncated here */ };

union tensor_union_0 {
    float tensor_7[1][4];
    float tensor_9[1][64];
    float tensor_11[1][64];
};
static union tensor_union_0 tu0;

union tensor_union_1 {
    float tensor_8[1][64];
    float tensor_10[1][64];
};
static union tensor_union_1 tu1;

static inline void node_Flatten_0(const float tensor_input[1][4], float tensor_7[1][4]) {
    /* Flatten*/
    float *input = (float *)tensor_input;
    float *output = (float *)tensor_7;
    for (uint32_t i = 0; i < 4; i++)
        output[i] = input[i];
}

static inline void node_Gemm_1(const float tensor_7[1][4], const float tensor_q_net_0_weight[64][4], const float tensor_q_net_0_bias[64], float tensor_8[1][64]) {
    /* Gemm */
    const int M = 1;
    const int K = 4;
    const int N = 64;
    float (*A)[4] = (float(*)[4])tensor_7;
    float (*Y)[64] = (float(*)[64])tensor_8;
    float alpha = 1.0f;
    float beta = 1.0f;
    float (*C)[64] = (float(*)[64])tensor_q_net_0_bias;
    for (uint32_t r = 0; r < M; r++)
        for (uint32_t c = 0; c < N; c++) {
            float ABrc = 0;
            for (uint32_t i = 0; i < K; i++) {
                float B = tensor_q_net_0_weight[c][i];
                ABrc += A[r][i] * B;
            }
            float tmp = ABrc * alpha;
            tmp += C[0][c] * beta;
            Y[r][c] = tmp;
        }
}

static inline void node_Relu_2(const float tensor_8[1][64], float tensor_9[1][64]) {
    /*Relu*/
    float *X = (float *)tensor_8;
    float *Y = (float *)tensor_9;
    for (uint32_t i = 0; i < 64; i++)
        Y[i] = X[i] > 0 ? X[i] : 0;
}

static inline void node_Gemm_3(const float tensor_9[1][64], const float tensor_q_net_2_weight[64][64], const float tensor_q_net_2_bias[64], float tensor_10[1][64]) {
    /* Gemm */
    const int M = 1;
    const int K = 64;
    const int N = 64;
    float (*A)[64] = (float(*)[64])tensor_9;
    float (*Y)[64] = (float(*)[64])tensor_10;
    float alpha = 1.0f;
    float beta = 1.0f;
    float (*C)[64] = (float(*)[64])tensor_q_net_2_bias;
    for (uint32_t r = 0; r < M; r++)
        for (uint32_t c = 0; c < N; c++) {
            float ABrc = 0;
            for (uint32_t i = 0; i < K; i++) {
                float B = tensor_q_net_2_weight[c][i];
                ABrc += A[r][i] * B;
            }
            float tmp = ABrc * alpha;
            tmp += C[0][c] * beta;
            Y[r][c] = tmp;
        }
}

static inline void node_Relu_4(const float tensor_10[1][64], float tensor_11[1][64]) {
    /*Relu*/
    float *X = (float *)tensor_10;
    float *Y = (float *)tensor_11;
    for (uint32_t i = 0; i < 64; i++)
        Y[i] = X[i] > 0 ? X[i] : 0;
}

static inline void node_Gemm_5(const float tensor_11[1][64], const float tensor_q_net_4_weight[2][64], const float tensor_q_net_4_bias[2], float tensor_output[1][2]) {
    /* Gemm */
    const int M = 1;
    const int K = 64;
    const int N = 2;
    float (*A)[64] = (float(*)[64])tensor_11;
    float (*Y)[2] = (float(*)[2])tensor_output;
    float alpha = 1.0f;
    float beta = 1.0f;
    float (*C)[2] = (float(*)[2])tensor_q_net_4_bias;
    for (uint32_t r = 0; r < M; r++)
        for (uint32_t c = 0; c < N; c++) {
            float ABrc = 0;
            for (uint32_t i = 0; i < K; i++) {
                float B = tensor_q_net_4_weight[c][i];
                ABrc += A[r][i] * B;
            }
            float tmp = ABrc * alpha;
            tmp += C[0][c] * beta;
            Y[r][c] = tmp;
        }
}

void entry(const float tensor_input[1][4], float tensor_output[1][2]) {
    node_Flatten_0(tensor_input, tu0.tensor_7);
    node_Gemm_1(tu0.tensor_7, tensor_q_net_0_weight, tensor_q_net_0_bias, tu1.tensor_8);
    node_Relu_2(tu1.tensor_8, tu0.tensor_9);
    node_Gemm_3(tu0.tensor_9, tensor_q_net_2_weight, tensor_q_net_2_bias, tu1.tensor_10);
    node_Relu_4(tu1.tensor_10, tu0.tensor_11);
    node_Gemm_5(tu0.tensor_11, tensor_q_net_4_weight, tensor_q_net_4_bias, tensor_output);
}