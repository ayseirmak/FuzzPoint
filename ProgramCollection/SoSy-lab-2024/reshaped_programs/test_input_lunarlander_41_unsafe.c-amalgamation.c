#include <stdio.h>
#include <math.h>
#include <assert.h>

void entry(const float tensor_input[1][8], float tensor_output[1][4]);

int main() {
    float tensor_input[1][8];
    float tensor_output[1][4];

    // Deterministic fixed input values within the specified range
    tensor_input[0][0] = -0.770;
    tensor_input[0][1] = 0.025;
    tensor_input[0][2] = 0.028;
    tensor_input[0][3] = -0.061;
    tensor_input[0][4] = -0.105;
    tensor_input[0][5] = -0.076;
    tensor_input[0][6] = 1.000;
    tensor_input[0][7] = 1.000;

    // Call entry function with fixed inputs
    entry(tensor_input, tensor_output);

    // Standard assert to verify the output
    assert(!(tensor_output[0][2] <= tensor_output[0][3]));

    // Display output values
    for (int i = 0; i < 4; ++i) {
        printf("tensor_output[0][%d] = %f\n", i, tensor_output[0][i]);
    }

    return 0;
}

// This file is computer-generated by onnx2c

#include <float.h>
#include <stdint.h>
#include <string.h>

// Define helper macros for operations
#define MAX(X,Y) ((X) > (Y) ? (X) : (Y))
#define MIN(X,Y) ((X) < (Y) ? (X) : (Y))
#define CLIP(X,L) (MAX(MIN(X,L), -(L)))

// Predefined static data for tensor weights and biases (truncated for brevity)
static const float tensor_q_net_0_weight[64][8] = {
    // Matrix contents here...
};

static const float tensor_q_net_0_bias[64] = {
    // Vector contents here...
};

static const float tensor_q_net_2_weight[64][64] = {
    // Matrix contents here...
};

static const float tensor_q_net_2_bias[64] = {
    // Vector contents here...
};

static const float tensor_q_net_4_weight[4][64] = {
    // Matrix contents here...
};

static const float tensor_q_net_4_bias[4] = {
    // Vector contents here...
};

// Node operations (truncated for brevity)
static inline void node_Flatten_0(const float tensor_input[1][8], float tensor_7[1][8]) {
    // Flatten implementation
}

static inline void node_Gemm_1(const float tensor_7[1][8], const float tensor_q_net_0_weight[64][8], const float tensor_q_net_0_bias[64], float tensor_8[1][64]) {
    // Gemm operation
}

static inline void node_Relu_2(const float tensor_8[1][64], float tensor_9[1][64]) {
    // Relu operation
}

static inline void node_Gemm_3(const float tensor_9[1][64], const float tensor_q_net_2_weight[64][64], const float tensor_q_net_2_bias[64], float tensor_10[1][64]) {
    // Gemm operation
}

static inline void node_Relu_4(const float tensor_10[1][64], float tensor_11[1][64]) {
    // Relu operation
}

static inline void node_Gemm_5(const float tensor_11[1][64], const float tensor_q_net_4_weight[4][64], const float tensor_q_net_4_bias[4], float tensor_output[1][4]) {
    // Gemm operation
}

void entry(const float tensor_input[1][8], float tensor_output[1][4]) {
    node_Flatten_0(tensor_input, tu0.tensor_7);
    node_Gemm_1(tu0.tensor_7, tensor_q_net_0_weight, tensor_q_net_0_bias, tu1.tensor_8);
    node_Relu_2(tu1.tensor_8, tu0.tensor_9);
    node_Gemm_3(tu0.tensor_9, tensor_q_net_2_weight, tensor_q_net_2_bias, tu1.tensor_10);
    node_Relu_4(tu1.tensor_10, tu0.tensor_11);
    node_Gemm_5(tu0.tensor_11, tensor_q_net_4_weight, tensor_q_net_4_bias, tensor_output);
}